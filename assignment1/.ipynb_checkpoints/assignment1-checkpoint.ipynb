{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "## Problem 2: Derive the sentiment of each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "#import tweet_sentiment as tweet\n",
    "import term_sentiment as term\n",
    "#from frequency import *\n",
    "#import happiest_state as happy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test extract_tweets function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"output.txt\") as tweet_file:\n",
    "    tweet_data = tweet.extract_tweets(tweet_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test extract_term_sentiment function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"AFINN-111.txt\") as sent_file:\n",
    "    term_sentiment = term.extract_term_sentiment(sent_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test build_tweet_dict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet_dict = tweet.build_tweet_dict(tweet_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test find_word_score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_list = ['omg', 'happy', 'sad']\n",
    "scores = tweet.find_word_score(word_list, term_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test calc_tweet_sentiment function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet_sentiment = term.calc_tweet_sentiment(tweet_dict, term_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problem 3: Derive the sentiment of new terms\n",
    "### Test deduce_word_sentiment function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_sentiment = term.deduce_word_sentiment(tweet_dict, tweet_sentiment, term_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problem 4: Compute term frequency\n",
    "### test calc_term_freq function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "term_freq = calc_term_freq(tweet_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problem 5: Which state is happiest?\n",
    "### Test extract_coordinates, extract_places, extract_users functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet_file_name = \"output.txt\"\n",
    "with open(tweet_file_name) as tweet_file:\n",
    "    tweet_coordinates = happy.extract_coordinates(tweet_file)\n",
    "with open(tweet_file_name) as tweet_file:\n",
    "    tweet_places = happy.extract_places(tweet_file)\n",
    "with open(tweet_file_name) as tweet_file:\n",
    "    tweet_users = happy.extract_users(tweet_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test match_coord_states function along with std_state function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet_coordinate1 = {u\"I'm at Backyard Cafe in San Diego, CA https://t.co/9X6BBJuSwe\":\n",
    "           [-117.115926, 32.763431]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u\"I'm at Backyard Cafe in San Diego, CA https://t.co/9X6BBJuSwe\": 'CA'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy.match_coord_states(tweet_coordinate1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test extract_states function along with std_state function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u\"I'm at Backyard Cafe in Texas\": 'TX'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_place1 = {u\"I'm at Backyard Cafe in Texas\":u'Texas, USA'}\n",
    "happy.extract_states(tweet_place1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u\"I'm at Backyard Cafe in Austin, TX\": u'TX'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_user1 = {u\"I'm at Backyard Cafe in Austin, TX\":u'Austin, TX'}\n",
    "happy.extract_states(tweet_user1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test determine_state function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coord = {'tweeting': 'CA'} # None\n",
    "place = {'tweeting': None} #'NJ'\n",
    "user = {'tweeting': 'OK'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweeting': 'CA'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy.determine_state(coord,place,user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test calc_state_avg_sentiment function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CA': 2.0, 'NJ': 0.0, 'NY': 2.5}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_sentiment = {'tweet1':3, 'tweet2':2, 'tweet3':0, 'tweet4':2}\n",
    "tweet_state = {'tweet1':'NY', 'tweet2':'CA', 'tweet3':'NJ', 'tweet4':'NY'}\n",
    "happy.calc_state_avg_sentiment(tweet_sentiment, tweet_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test overall performance by call main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WV\n"
     ]
    }
   ],
   "source": [
    "happy.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problem 6: Top ten hash tags\n",
    "### Test count_hashtags and print_top_ten function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import top_ten as top\n",
    "tweet_file_name = 'output.txt'\n",
    "with open(tweet_file_name) as tweet_file:\n",
    "    hashtag_count = top.count_hashtags(tweet_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALDUBHappyBdayLOLA 69.0\n",
      "MadeInTheAM 62.0\n",
      "ShowtimeHarana 50.0\n",
      "FR1DAY13BR 46.0\n",
      "ModiAtWembley 29.0\n",
      "PushAwardsKathNiels 24.0\n",
      "TvKanallarıKapatılıyor 18.0\n",
      "Purpose 17.0\n",
      "purpose 16.0\n",
      "NicoEstamosConVOS 12.0\n"
     ]
    }
   ],
   "source": [
    "top.print_top_ten(hashtag_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
